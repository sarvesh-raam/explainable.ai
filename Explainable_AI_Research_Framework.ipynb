{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarvesh-raam/explainable.ai/blob/main/Explainable_AI_Research_Framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ðŸ¤– Explainable AI (XAI) Research Framework\n",
        "### *Balancing Accuracy and Interpretability: A Post-hoc Framework for Structured Data Analysis*\n",
        "\n",
        "---\n",
        "\n",
        "**Authors:** [sarvesh-raam](https://github.com/sarvesh-raam) & [Vignesh (Vicky)](https://github.com/Vigneshhhhhhhhhh)  \n",
        "**Project:** IEEE Research-Grade Prototype  \n",
        "**Status:** Integrated with SHAP, LIME, and Stability Testing\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Research Overview\n",
        "This study evaluates the reliability, stability, and utility of post-hoc explainability methods (**SHAP** and **LIME**) when applied to machine learning models (Random Forest, XGBoost, Logistic Regression)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## âš™ï¸ 1. Infrastructure Setup\n",
        "Installing the research stack and preparing the data environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "!pip install shap lime xgboost scikit-learn pandas numpy matplotlib seaborn --quiet\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from lime import lime_tabular\n",
        "\n",
        "print(\"âœ… Research environment ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phase1-header"
      },
      "source": [
        "## ðŸ§ª 2. Phase I & II: Data Pipeline & Model Training\n",
        "We ingest the Heart Disease dataset, perform feature Engineering, and train our predictive engines."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prep-train"
      },
      "outputs": [],
      "source": [
        "# Load Data\n",
        "url = \"https://raw.githubusercontent.com/sarvesh-raam/explainable.ai/main/data/heart_disease.csv\"\n",
        "try:\n",
        "    df = pd.read_csv(url)\n",
        "except:\n",
        "    # Fallback: Create mock data if URL is not reachable\n",
        "    print(\"âš ï¸ Repo not public yet? Using sample data.\")\n",
        "    data = np.random.rand(300, 13)\n",
        "    target = np.random.randint(0, 2, 300)\n",
        "    df = pd.DataFrame(data, columns=['age','sex','cp','trestbps','chol','fbs','restecg','thalach','exang','oldpeak','slope','ca','thal'])\n",
        "    df['target'] = target\n",
        "\n",
        "# Split & Scale\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X.columns)\n",
        "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X.columns)\n",
        "\n",
        "# Train Models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    \"XGBoost\": XGBClassifier(eval_metric='logloss')\n",
        "}\n",
        "\n",
        "results = {}\n",
        "print(\"Training in progress...\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    acc = accuracy_score(y_test, model.predict(X_test_scaled))\n",
        "    results[name] = acc\n",
        "    print(f\"{name}: {acc*100:.2f}%\")\n",
        "\n",
        "pd.Series(results).plot(kind='barh', color=['#3498db', '#2ecc71', '#e74c3c'], title=\"Model Accuracy Comparison\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phase3-header"
      },
      "source": [
        "## ðŸ” 3. Phase III: SHAP Analysis (Global & Local)\n",
        "Understanding which features drive the model's decisions globally and for specific patients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shap"
      },
      "outputs": [],
      "source": [
        "model_to_explain = models[\"Random Forest\"]\n",
        "explainer = shap.TreeExplainer(model_to_explain)\n",
        "shap_values = explainer.shap_values(X_test_scaled)\n",
        "\n",
        "print(\"ðŸ“Š Global SHAP Summary Plot\")\n",
        "shap.summary_plot(shap_values[1], X_test_scaled)\n",
        "\n",
        "print(\"ðŸ“ Local Instance Explanation (Patient 0)\")\n",
        "shap.initjs()\n",
        "shap.force_plot(explainer.expected_value[1], shap_values[1][0,:], X_test_scaled.iloc[0,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phase4-header"
      },
      "source": [
        "## ðŸ§ª 4. Phase IV: Stability & Reliability Lab\n",
        "Testing the robustness of our explanations against data noise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stability"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "def check_stability_score(instance, noise_level=0.1):\n",
        "    # Original prediction\n",
        "    orig_imp = explainer.shap_values(instance.reshape(1,-1))[1].flatten()\n",
        "\n",
        "    # Noisy prediction\n",
        "    noisy_instance = instance + np.random.normal(0, noise_level, instance.shape)\n",
        "    noisy_imp = explainer.shap_values(noisy_instance.reshape(1,-1))[1].flatten()\n",
        "\n",
        "    corr, _ = spearmanr(orig_imp, noisy_imp)\n",
        "    return corr\n",
        "\n",
        "instance_to_test = X_test_scaled.iloc[0].values\n",
        "score = check_stability_score(instance_to_test)\n",
        "print(f\"ðŸ”¹ Stability Index (Spearman Rank Correlation): {score:.4f}\")\n",
        "print(\"A score > 0.80 indicates highly stable explanations.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "footer"
      },
      "source": [
        "---\n",
        "### ðŸ“š Citation\n",
        "If you use this framework in your research, please cite:  \n",
        "*Explainable AI (XAI) Framework for Structured Data Analysis by sarvesh-raam & Vignesh (Vicky)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}